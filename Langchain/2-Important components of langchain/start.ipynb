{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". Get setup with langchain,langsmith and langserve\n",
    "\n",
    ". use the  basic and common componentsof langchain : prompt templates, models d output parsers\n",
    "\n",
    ". build a simple application with langchain\n",
    "\n",
    ". tracing eith langsmith\n",
    "\n",
    ". serve your application with langserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key2 = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_langchain = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# âœ… Ensure 'LANGCHAIN_PROJECT' is not None before setting it\n",
    "langchain_project = os.getenv(\"LANGCHAIN_PROJECT\", \"default_project\")  # ðŸ‘ˆ Provide a default value\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = langchain_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x10dd7aad0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10dd84be0> root_client=<openai.OpenAI object at 0x10dd78d00> root_async_client=<openai.AsyncOpenAI object at 0x10dd7ab30> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm  = ChatOpenAI(api_key=api_key2,model=\"gpt-4o-mini\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##input and response\n",
    "result = llm.invoke(\"what is robotic AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robotic AI refers to the integration of artificial intelligence (AI) with robotics to create machines that can perform tasks autonomously or with minimal human intervention. This combination enables robots to not only follow programmed instructions but also adapt to their environments, learn from their experiences, make decisions, and execute complex actions. \n",
      "\n",
      "Key aspects of robotic AI include:\n",
      "\n",
      "1. **Perception**: Robots equipped with sensors (cameras, LIDAR, etc.) can collect data from their surroundings. AI algorithms process this data to recognize objects, navigate spaces, and understand the environment.\n",
      "\n",
      "2. **Cognition**: AI enables robots to process information and make decisions based on their understanding of the environment. This could involve problem-solving, reasoning, and learning from past experiences.\n",
      "\n",
      "3. **Actuation**: Robots use actuators (motors, servos) to physically interact with the world. AI can enhance the control of these actuators, enabling smoother and more precise movements.\n",
      "\n",
      "4. **Learning**: Machine learning techniques allow robots to improve their performance over time by learning from data and experiences. This can include reinforcement learning, where robots learn optimal behaviors through trial and error.\n",
      "\n",
      "5. **Autonomy**: Robotic AI systems can operate independently in dynamic environments, making real-time decisions based on their objectives and constraints.\n",
      "\n",
      "Robotic AI has applications across various fields including manufacturing (automation), healthcare (surgical robots), logistics (autonomous vehicles), service industries (delivery robots, cleaning robots), and many others. The goal is to improve efficiency, safety, and capability in tasks traditionally carried out by humans.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an AI expert engineer.Provide answers based on question '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##promt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\",\"you are an AI expert engineer.Provide answers based on question \"),\n",
    "    (\"user\",\"{input}\")\n",
    "]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After robotic AI, several advancements and fields of research are anticipated to emerge or develop further. These include:\n",
      "\n",
      "1. **Autonomous Systems**: Beyond robotic AI, the focus will shift towards fully autonomous systems that can perform complex tasks without human intervention, such as autonomous vehicles, drones, and smart factories.\n",
      "\n",
      "2. **Human-Robot Collaboration**: This area will involve designing robots that can work alongside humans safely and effectively, improving productivity while enhancing human capabilities.\n",
      "\n",
      "3. **Neurosymbolic AI**: This approach combines neural networks with symbolic reasoning, which can lead to more interpretable and robust AI systems capable of understanding complex tasks better than current AI.\n",
      "\n",
      "4. **General Artificial Intelligence (AGI)**: Research aimed at developing AGI, which would possess human-like cognitive abilities across various tasks, is a long-term goal that goes beyond current specialized AI systems.\n",
      "\n",
      "5. **Emotionally Intelligent AI**: Development of AI systems that can understand and respond appropriately to human emotions, leading to more adaptive interaction in fields like healthcare, customer service, and education.\n",
      "\n",
      "6. **Swarm Intelligence**: Inspired by natural systems (like flocks of birds or colonies of ants), swarm intelligence studies how large numbers of simple agents can work together to solve complex problems.\n",
      "\n",
      "7. **Quantum Computing and AI**: The intersection of quantum computing and AI could lead to powerful advancements, enabling faster processing and more sophisticated algorithms that could solve problems currently out of reach.\n",
      "\n",
      "8. **Explainable AI (XAI)**: As AI systems become more complex, the need for transparency and interpretability will grow. Research in XAI aims to make AI decision-making processes clearer to users.\n",
      "\n",
      "9. **Ethical and Societal AI**: The focus will increasingly shift to the ethical implications of AI and robotics, ensuring that these technologies are developed and implemented responsibly, prioritizing human welfare.\n",
      "\n",
      "10. **Biohybrid Systems**: Integrating biological systems with robotic systems could lead to innovative solutions in areas like medicine and environmental monitoring.\n",
      "\n",
      "11. **Integration with IoT (Internet of Things)**: Combining AI with IoT can enhance data analysis capabilities and enable smarter, more efficient systems in smart cities, industrial operations, and personal devices.\n",
      "\n",
      "These areas represent some of the potential trajectories for future AI advancements beyond what is currently being achieved with robotic AI. Each advancement presents both exciting opportunities and challenges that will need to be navigated as technology evolves.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\":\"can you tell me what is furthur advancement after robotic AI to be done? i mean which is state is next after robotic AI\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the current advancements in robotic AI, several potential areas for further advancement can be identified:\n",
      "\n",
      "1. **Autonomous Systems**: Further development of fully autonomous systems that can operate without human intervention across various environments and tasks, such as self-driving cars or autonomous drones.\n",
      "\n",
      "2. **Cognitive Robotics**: Enhancing the cognitive capabilities of robots, allowing them to understand context, learn from experiences, and make decisions based on unstructured data. This involves integrating advanced machine learning and natural language processing.\n",
      "\n",
      "3. **Emotional and Social Intelligence**: Developing robots with the ability to recognize and respond to human emotions, which could lead to more effective human-robot interaction in healthcare, education, and companionship.\n",
      "\n",
      "4. **Collaborative Robots (Cobots)**: Advancing robots that work alongside humans in shared spaces, improving safety, communication, and productivity in industrial and home environments.\n",
      "\n",
      "5. **Swarm Robotics**: Exploring collective behavior in robotics, where multiple robots collaborate to complete tasks, inspired by social insects and natural systems.\n",
      "\n",
      "6. **Integration with the Internet of Things (IoT)**: Creating systems that allow robots to communicate and coordinate with other smart devices, thus enhancing their capabilities in smart homes and smart cities.\n",
      "\n",
      "7. **Neuroscience-Inspired Approaches**: Developing robots based on principles from neuroscience, such as artificial general intelligence (AGI), where robots possess cognitive abilities similar to human beings.\n",
      "\n",
      "8. **Biohybrid Robotics**: Researching the integration of biological components with robotic systems, potentially leading to more adaptive and resilient robots.\n",
      "\n",
      "These advancements could lead to robots that are not only more intelligent and autonomous but also capable of performing complex tasks in an increasingly human-like manner.\n"
     ]
    }
   ],
   "source": [
    "### string output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"can you tell me what is furthur advancement after robotic AI to be done? i mean which is state is next after robotic AI\"})\n",
    "print(response) ##no need for .content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
