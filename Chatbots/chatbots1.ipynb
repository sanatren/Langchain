{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a chatbot\n",
    "\n",
    "### what we will build will only use the language models to have a conversation\n",
    "\n",
    ">enabale chatbot bot expirence over an external source of data using conversational RAG\n",
    "\n",
    ">will build a chatbot that can do actions using agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10feaa260>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10feabfd0>, root_client=<openai.OpenAI object at 0x10ee80580>, root_async_client=<openai.AsyncOpenAI object at 0x10feaa290>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\",openai_api_key=openai_api_key)\n",
    "\n",
    "#model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Sanatan! It's great to hear about your academic pursuits in AI/ML and Computer Science. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 41, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-85362405-fcc8-48ff-a682-01def5e5aafd-0' usage_metadata={'input_tokens': 41, 'output_tokens': 29, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response = model.invoke([HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\")])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Of course! Here are a few tips to help you find an internship in your field:\\n\\n1. Update your resume and LinkedIn profile to highlight your skills and experience in AI/ML and Computer Science.\\n\\n2. Reach out to your college's career services office for guidance and resources on finding internships.\\n\\n3. Network with professionals in your field through LinkedIn, industry events, and networking events to learn about potential internship opportunities.\\n\\n4. Check job boards, company websites, and social media platforms for internship postings in AI/ML and Computer Science.\\n\\n5. Consider reaching out to companies directly to inquire about potential internship opportunities, even if they don't have any posted.\\n\\nGood luck with your internship search, Sanatan! If you need any more assistance, feel free to ask.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 155, 'prompt_tokens': 90, 'total_tokens': 245, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-799fa957-ab05-4082-ba8e-0b5e47d06dd2-0', usage_metadata={'input_tokens': 90, 'output_tokens': 155, 'total_tokens': 245, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\"),\n",
    "        AIMessage(content=\"Hello Sanatan! It's great to hear about your academic pursuits in AI/ML and Computer Science. How can I assist you today?\"),\n",
    "        HumanMessage(content=\"I am looking for an internship Can you help me with that?\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message History\n",
    "we can use a message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore.\n",
    "Future interactions will then load those messages and pass them into chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "#this function will get the stored chat history based on the sessions id to distinguist between different chat sessions\n",
    "\n",
    "history = {}\n",
    "def get_session_history(sessions_id:str)->BaseChatMessageHistory:\n",
    "    if sessions_id not in history:\n",
    "        history[sessions_id] = ChatMessageHistory() ## whatever the chat is happening it will automatically go inside the history dictionary to store the chat history\n",
    "    return history[sessions_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat_1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\"),\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's great! It sounds like you have a strong foundation in technology and are exploring some cutting-edge fields like AI/ML. If you have any questions or need assistance with your studies or projects in these areas, feel free to ask. I'm here to help!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in Computer Science. This means you are currently pursuing a degree in technology with a focus on artificial intelligence and machine learning, as well as studying various aspects of computer science. \\n\\nAs a student, you are likely engaged in learning about programming, algorithms, data structures, and other key topics in your field. You may also be working on projects or assignments related to AI/ML, applying theoretical knowledge to real-world problems. If you have any specific questions or need guidance on any academic or technical topics, feel free to share and I'll do my best to assist you.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 183, 'total_tokens': 327, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-33dc8401-e307-4534-82e7-238dc8966b36-0', usage_metadata={'input_tokens': 183, 'output_tokens': 144, 'total_tokens': 327, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"who i am and what i do\"),\n",
    "    ],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change the config to chat2 to change the session id to check if the chat history is stored or not\n",
    "\n",
    "config_1 = {\"configurable\":{\"session_id\":\"chat_2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I do not have the ability to know or remember specific individuals. Each interaction I have with a user is based solely on the input provided to me during that conversation. I am here to assist you with any questions or tasks you may have to the best of my ability based on the information available to me.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"do you know me?\"),\n",
    "    ],\n",
    "    config=config_1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "\n",
    "Promopt templates help to turn raw user information into a format that the LLM can work with . in this case , the raw user input is just the message , which we are passing to the LLM . Let's now make that a bit more complicated .\n",
    "\n",
    "First . let's add in a system message with some custom instructions(but still taking messages as input).Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatMessagePromptTemplate,MessagesPlaceholder,ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"you are a helpful assistant.answer all the question to the best of your ability\"\n",
    "         ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello, Sanatan! It's great to meet you. How can I assist you with your studies or any other questions you might have related to AI/ML, CS, or anything else?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 60, 'total_tokens': 100, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2bc1903a-e602-4a7d-be91-eb4e4a983bc8-0', usage_metadata={'input_tokens': 60, 'output_tokens': 40, 'total_tokens': 100, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## invokeing with chat message history\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello Sanatan! It's great to hear about your academic background and specialization. How can I assist you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 1816, 'total_tokens': 1840, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-00438d73-a0c0-4f89-8154-bb24c70187d1-0' usage_metadata={'input_tokens': 1816, 'output_tokens': 24, 'total_tokens': 1840, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "config_2 = {\"configurable\": {\"session_id\": \"chat_3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\")],\n",
    "        \n",
    "    },\n",
    "    config=config_2\n",
    "    \n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sanatan! It's great to hear about your academic background and specialization. How can I assist you today?\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"what is my name?\"),\n",
    "    ],\n",
    "    config=config_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Sanatan Khemariya. How can I assist you further, Sanatan?'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding language specific responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can make it more compleax (as we can insert a language parameter to talk in certain message)\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate,MessagesPlaceholder,ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all questions in {language}. Always respond in {language}.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response in desired language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्कार, Sanatan Khemariya! आपका स्वागत है। आपकी वर्णित में मैं आपको सहायक बनाने में भविष्यवाणी कर सकता हूँ। कैसे मदद कर सकता हूँ?'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to set default languge as english if no parameter is passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store both chat history and session language\n",
    "session_data = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> ChatMessageHistory:\n",
    "    \"\"\"\n",
    "    Retrieves chat history for a given session, initializing if necessary.\n",
    "    \"\"\"\n",
    "    if session_id not in session_data:\n",
    "        session_data[session_id] = {\"history\": ChatMessageHistory(), \"language\": \"English\"}  # Default language\n",
    "    return session_data[session_id][\"history\"]\n",
    "\n",
    "def set_session_language(session_id: str, language: str):\n",
    "    \"\"\"Ensure each session correctly remembers the preferred language.\"\"\"\n",
    "    if session_id not in session_data:\n",
    "        session_data[session_id] = {\"history\": ChatMessageHistory(), \"language\": language}\n",
    "    else:\n",
    "        # ✅ Only update language if it's not already set\n",
    "        if \"language\" not in session_data[session_id]:\n",
    "            session_data[session_id][\"language\"] = language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_with_language(session_id: str, messages, language=None):\n",
    "    \"\"\"Handles chatbot invocation while ensuring memory & language persistence.\"\"\"\n",
    "    if session_id not in session_data:\n",
    "        set_session_language(session_id, \"English\")  # ✅ Default to English\n",
    "\n",
    "    if language is None:\n",
    "        language = session_data[session_id][\"language\"]  # ✅ Retrieve stored language\n",
    "\n",
    "    set_session_language(session_id, language)  # ✅ Ensure language is remembered\n",
    "\n",
    "    response = with_message_history.invoke(\n",
    "        {\n",
    "            \"messages\": messages,\n",
    "            \"language\": language  # ✅ Ensures correct language is passed\n",
    "        },\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_4 = {\"configurable\":{\"session_id\":\"chat_4\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in Hindi: नमस्ते, सनातन खेमरिया। आपका स्वागत है। आपका किसी विषय पर सवाल है क्या?\n"
     ]
    }
   ],
   "source": [
    "response1 = invoke_with_language(\n",
    "    session_id=\"chat_3\",\n",
    "    messages=[HumanMessage(content=\"Hi, I am Sanatan Khemariya, a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\")],\n",
    "    language=\"Hindi\"\n",
    ")\n",
    "\n",
    "print(\"Response in Hindi:\", response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते, सनातन खेमरिया। आपका स्वागत है। आपका किसी विषय पर सवाल है क्या?'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in Hindi: आपका नाम सनातन खेमरिया है।\n"
     ]
    }
   ],
   "source": [
    "response2 = invoke_with_language(\n",
    "    session_id=\"chat_3\",\n",
    "    messages=[HumanMessage(content=\"What's my name?\")]\n",
    ")\n",
    "\n",
    "print(\"Response in Hindi:\", response2.content)  # ✅ Should still reply in Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in Hindi: Your name is Sanatan Khemariya.\n"
     ]
    }
   ],
   "source": [
    "response2 = invoke_with_language(\n",
    "    session_id=\"chat_3\",\n",
    "    messages=[HumanMessage(content=\"What's my name?\")],\n",
    "    language=\"English\"\n",
    ")\n",
    "\n",
    "print(\"Response in Hindi:\", response2.content)  # changed the language to english now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in Hindi: You are a B.Tech 3rd year student specializing in micro degrees in AI/ML and majoring in CS.\n"
     ]
    }
   ],
   "source": [
    "response2 = invoke_with_language(\n",
    "    session_id=\"chat_3\",\n",
    "    messages=[HumanMessage(content=\"what is my profession\")]\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Response in Hindi:\", response2.content)  # now should reply in englis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in Hindi: You previously asked me, \"What's my name?\"\n"
     ]
    }
   ],
   "source": [
    "response2 = invoke_with_language(\n",
    "    session_id=\"chat_3\",\n",
    "    messages=[HumanMessage(content=\"what i asked previously from you\")],\n",
    "    language=\"Hindi\"\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Response in Hindi:\", response2.content)  # now should reply in hindi with remembering previous context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing the conversation history\n",
    "\n",
    "One more important concept to understand when builsding chatbots is how  to manage the conversation history.if left unmanaged , the list of messages will grow unbounded and potentialy overflow the context window of the the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the trim_messages helper to reduce how many messages we're sending to the model. the trimmer allows us to specify how many tokens we want to keep , along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom token counter function (alternative to model.get_num_tokens)\n",
    "def token_counter(messages):\n",
    "    \"\"\"Simple token counter using text length approximation\"\"\"\n",
    "    return sum(len(msg.content.split()) for msg in messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=1000,  \n",
    "    strategy=\"last\",   \n",
    "    include_system=True,  \n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    "    token_counter=token_counter #work on the token counter function\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content=\"Hi, I am Bob.\"),\n",
    "    SystemMessage(content=\"Hi Bob! How can I assist you today?\"),\n",
    "    HumanMessage(content=\"I need help with my resume.\"),\n",
    "    AIMessage(content=\"Of course! What field are you applying for?\"),\n",
    "    HumanMessage(content=\"Software Engineering.\"),\n",
    "    AIMessage(content=\"Great! Do you have any experience in programming languages like Python or Java?\"),\n",
    "    HumanMessage(content=\"Yes, I have worked with both.\"),\n",
    "    AIMessage(content=\"That's great! I suggest highlighting your experience with Python and Java in your skills section.\"),\n",
    "    HumanMessage(content=\"Should I include personal projects?\"),\n",
    "    AIMessage(content=\"Absolutely! Personal projects show initiative and problem-solving skills.\"),\n",
    "    HumanMessage(content=\"How should I format my resume?\"),\n",
    "    AIMessage(content=\"Use a clean, structured layout with sections like Summary, Skills, Experience, and Projects.\"),\n",
    "    HumanMessage(content=\"Thanks! That helps a lot.\"),\n",
    "    AIMessage(content=\"You're welcome! Let me know if you need further guidance.\"),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi, I am Bob.', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='Hi Bob! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I need help with my resume.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Of course! What field are you applying for?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Software Engineering.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Great! Do you have any experience in programming languages like Python or Java?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Yes, I have worked with both.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's great! I suggest highlighting your experience with Python and Java in your skills section.\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Should I include personal projects?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Absolutely! Personal projects show initiative and problem-solving skills.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How should I format my resume?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Use a clean, structured layout with sections like Summary, Skills, Experience, and Projects.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks! That helps a lot.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"You're welcome! Let me know if you need further guidance.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'बिलकुल! क्या मुझे आपकी कुछ पसंदीदा चीजों के बारे में बता सकते हैं?'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"messages\": messages + [HumanMessage(content=\"can you give me a cool and catchy nick name\")],\n",
    "              \"language\": \"Hindi\"\n",
    "              })\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chain with session history\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "\n",
    "# Define session configuration\n",
    "config_5 = {\"configurable\": {\"session_id\": \"chat_5\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response in English: Sure, Bob! How about \"Bobster\"?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Hi, I am Bob.\"),\n",
    "            SystemMessage(content=\"Hi Bob! How can I assist you today?\"),\n",
    "            HumanMessage(content=\"Can you give me a cool and catchy nickname?\")\n",
    "        ],\n",
    "        \"language\": \"English\"\n",
    "    },\n",
    "    config=config_5\n",
    ")\n",
    "\n",
    "print(\"Response in English:\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
